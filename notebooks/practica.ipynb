{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos algunas librerias que vamos a utilizar luego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:13:37.899002822Z",
     "start_time": "2023-08-07T14:13:37.139971848Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.utils import load_dataset, split_data, DataLoader\n",
    "from src.text import standardize_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indice orden:\n",
    "\n",
    "- (1) Presentación de oportunidad. (Cubiertos en la sesion de metodologia)\n",
    "- (2) Medición del posible impacto. (Cubiertos en la sesion de metodologia)\n",
    "- (3) Criterios de éxito:\n",
    "    - 3.a Métricas del modelo\n",
    "    - 3.b Métricas de negocio (Cubiertos en la sesion de metodologia)\n",
    "- (4) Recolección de datos y prueba de hipótesis (Partimos de datos)\n",
    "- (5) Exploración de los datos. \n",
    "- (6) Modelo de base.\n",
    "- (7) Prototipado.\n",
    "- (8) Encontrado la arquitectura -> búsqueda de hiper-parámetros -> Entrenamiento. (Por ahora fuera del alcance)\n",
    "- (9) Despliegue en producción. (Por ahora fuera del alcance)\n",
    "- (10) Monitoreo. (Por ahora fuera del alcance)\n",
    "- (11) A/B testing. (Por ahora fuera del alcance)\n",
    "- (12) Concluciones con respecto a los criterios de exito -> reunion con stakeholders. (Por ahora fuera del alcance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:14:10.683627902Z",
     "start_time": "2023-08-07T14:13:37.370445164Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"../datasets/awzm_products.jsonl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:14:11.718020256Z",
     "start_time": "2023-08-07T14:14:11.681798541Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Criterios de éxito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance\n",
    "\n",
    "Sabemos que el problema se puede clasificar como un problema de multiclass donde un producto puede pertenecer a un numero de clases\n",
    "\n",
    "Es nuestro dataset balanceado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:14:12.094422446Z",
     "start_time": "2023-08-07T14:14:11.791576238Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_categories = dataset.main_cat.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:14:12.288033222Z",
     "start_time": "2023-08-07T14:14:12.045067556Z"
    }
   },
   "outputs": [],
   "source": [
    "main_cat_count_df = dataset.groupby(by=\"main_cat\").main_cat.count().reset_index(name=\"count\").sort_values(by=\"count\", ascending=True)\n",
    "\n",
    "main_cat_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:14:12.542260421Z",
     "start_time": "2023-08-07T14:14:12.369124187Z"
    }
   },
   "outputs": [],
   "source": [
    "main_categories_count = dataset.main_cat.unique().shape[0]\n",
    "\n",
    "equal_representation_count = int(dataset.shape[0]/main_categories_count)\n",
    "\n",
    "print(f\"Tenemos : {main_categories_count} Si estruviera balanceado esperariamos ver {equal_representation_count} samples por categoria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Porcentaje de representacion con respecto a lo esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T14:14:12.542418476Z",
     "start_time": "2023-08-07T14:14:12.464411791Z"
    }
   },
   "outputs": [],
   "source": [
    "main_cat_count_df[\"%\"] = main_cat_count_df[\"count\"]/equal_representation_count\n",
    "main_cat_count_df[\"diferencia%\"] = main_cat_count_df[[\"%\"]]-1\n",
    "\n",
    "main_cat_count_df.sort_values(by=\"diferencia%\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Metricas de exito sobre el rendimiento del modelo:\n",
    "\n",
    "Sabemos que no se encuentra balanceado con lo cual tenemos que tomar una metrica de evaluación que tenga encuenta ese desbalance en este caso vamos utilizar ***F1 Score weighted*** para evaluar los modelos.\n",
    "\n",
    "## 3b. Como metrica de negocio:\n",
    "Nos interesa entender el costo de las desiciones que toma el modelo. Y cuanto tiempo estamos reduciendo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Omitimos los pasos 4 y 5 ya que el dataset lo tenemos listo para entrenar.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Exploración de los datos.\n",
    "\n",
    "En principio no vamos a tener mucho tiempo para esta parte pero sepan que es donde vemos que features podemos usar y cual seria la mejor forma de procesarlas para que el modelo las pueda usar.\n",
    "\n",
    "Vamos a partir de que el titulo es nuestro primer candidato por varias razones:\n",
    "- Es un campo obligatorio\n",
    "- Cumple el fin de resumir y expresar al mismo tiempo la mayor cantidad de informacion posible sobre el producto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Modelo base (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split de los datos:\n",
    "\n",
    "Primero vamos a separa los datos que tenemos utilizando una division de 98% training /1% validacion y /1% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_val, Y_val), (X_test, Y_test) = split_data(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones\n",
    "\n",
    "Aqui pueden idear el baseline que deseen, puede ser algo completamente random, pueden predecir siempre una clase quizas la mas representada por ejemplo o algun otro que se les ocurra.\n",
    "El punto importante es tener algo sobre lo cual comparar el resultado del primer modelo que va a ser el mas sensillo pero que aun asi deberia superar ampliamente al baseline\n",
    "\n",
    "Esta prueba de como funciona un baseline lo vamos a hacer sobre Y_val para poder comprar luego con nuestro modelo sobre el mismo set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recueden de no pisar el contenido de Y_val\n",
    "import copy\n",
    "\n",
    "# aqui van las predicciones de ustedes que pueden ser puro random o alguna clase en particular.\n",
    "test_labels_copy = #\n",
    "\n",
    "# np.random.shuffle(test_labels_copy)\n",
    "\n",
    "# Calculamos los aciertos\n",
    "match_labels = Y_val == test_labels_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_val, test_labels_copy, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El numero que nos interesa es el que se encuentra en \"weighted avg\" y \"f1-score\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7) prototipado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para realizar el prototipo tenemos que recordar algunas cosas\n",
    "\n",
    "Es un problema de clasificación múltiple con lo cual es no nos dice que tipo de funcion de costo debemos usar y en segundo lugar la métrica a superar es la del modelo base en principio.\n",
    "En caso de que no podamos superar esa metrica, debemos volver a las hipotesis y replantear el prototipo, quizas necesitemos otra arquitectura o un modelo mas grande.\n",
    "\n",
    "\n",
    "En principio vamos a utilizar lo mas simple posible que es un modelo con un proceso de **multi_one_hot**. Pueden probar otro modelo u otro preproceso como tf-idf por ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre Preproceso\n",
    "\n",
    "Vamos a elimiar del titulo los emojis si es que hay y signos de puntuación ademas de reemplazar los numeros por un token que indica que hay un numero en ese lugar.\n",
    "\n",
    "Para ello vamos a utilizar el **DataLoader** que nos va a proporcionar los sets de entrenamiento, validacion y testing.\n",
    "\n",
    "En principio vamos a utilizar un vocabulario de 10000 tokens con un bache de 1024. Pueden modificarlo ampliar/reducir tanto el vocabulario como el batch_size, este ultimo va a determinar cuantos\n",
    "samples se utilzan para entrenar en forma simultanea, si reciben un error de OOM pueden reducir. Si en cambio notan que su GPU no se encuentra con mucha carga pueden ampliarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(vocab_size=10000, classes=22, batch_size=1024)\n",
    "\n",
    "data = data_loader.build_datasets(\"../datasets/awzm_products.jsonl.gz\")\n",
    "\n",
    "train_dataset = data[\"train\"]\n",
    "val_dataset = data[\"validation\"]\n",
    "test_dataset = data[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Prototipo\n",
    "\n",
    " En un principio pueden elegir el modelo que quieran con las capas, unidades y activaciones que deseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Espacio para agregar las capas que crean necesarias\n",
    "    # recuerden que si o si tienen que terminar con una salida de una funcion de densidad de probabilidad (softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer el entrenamiento mas rapido y eficiente pueden usar los siguientes callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\"temporal_checkpoint\",\n",
    "                                                      save_weights_only=True,\n",
    "                                                      save_only_best=True,\n",
    "                                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  # Tienen que definir una loss function\n",
    "  loss=tf.keras.losses.categorical_crossentropy,\n",
    "  # puden usar el optimizer que deseen\n",
    "  optimizer=#\n",
    "  # la metrica va a ser F1-score weighted por lo que encontramos sobre el desbalance de las clases\n",
    "  metrics=[tf.keras.metrics.F1Score(average=\"weighted\", threshold=None, name='f1_score', dtype=None)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hora de entrenar\n",
    "\n",
    "Si todo salio bien ahora van a poder entrenar un modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=500,\n",
    "    callbacks=[model_checkpoint, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregamos la capa de vectorizacion al modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El data_loader tiene una capa de vetorizacion, que usamos para crear el dataset previamente y preprocesar los datos.\n",
    "Ahora necesitamos esa capa para el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH=\"model_repositories\"\n",
    "MODEL_VERSION=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.text_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.text_vectorizer([\"ps5\", \"tv lg c2 with cover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append(data_loader.text_vectorizer)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layers.append(layer)\n",
    "\n",
    "final_model = tf.keras.Sequential([tf.keras.Input(shape=(),dtype=\"string\")]+layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspeccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(final_model, f\"{MODEL_PATH}/{MODEL_VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisamos que este bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text import translate_table\n",
    "\n",
    "reconstructed_model = tf.saved_model.load(f\"{MODEL_PATH}/{MODEL_VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text import classes_table\n",
    "\n",
    "classes_table.lookup(tf.constant([\"Tools & Home Improvement\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_table.lookup(tf.constant([11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisamos que nos de el mismo resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.argmax(reconstructed_model(tf.constant([\"Nintendo 64 cartridge\"]), training=False), axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_table.lookup(tf.constant([tf.argmax(reconstructed_model(tf.constant([\"Nintendo 64 cartridge\"]), training=False), axis=1).numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_table.lookup(tf.constant([tf.argmax(reconstructed_model(tf.constant([\"Nintendo 64 cartridge\"]), training=False), axis=1).numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armado de docker\n",
    "\n",
    "## (1) Creen un archivo que se llame dockerfile en esta carpeta notebooks\n",
    "Lo pueden hacer desde el editor o ejecutar en la siguiente celda:\n",
    "```\n",
    "    ! touch dockerfile\n",
    "```\n",
    "\n",
    "## (2) Copien esto en el dockerfile\n",
    "```\n",
    "    FROM tensorflow/serving:2.13.0\n",
    "    COPY model_repositories /models/category_classifier\n",
    "    ENV MODEL_NAME=category_classifier\n",
    "```\n",
    "Estamos indicando que vamos a usar la imagen 2.13.0 de tensorflow/serving\n",
    "Copiamos el modelo a /models/category_classifier en la imagen de docker\n",
    "Seteamos la variable MODEL_NAME a category_classifier\n",
    "\n",
    "## (3) Ahora procedemos a hacer un build del docker file con:\n",
    "```\n",
    "    build -t <nombre docker> .\n",
    "```\n",
    "Aqui si usamos nuestro <nombre de usuario>/nombre_imagen podemos luego con push subirlo a docker hub\n",
    "\n",
    "## (4) Ejecutarlo:\n",
    "```\n",
    "    docker run -t --rm -p 8501:8501 <nombre docker>\n",
    "```\n",
    "\n",
    "## (5) probarlo con curl o con el script en usage_api_example.py\n",
    "\n",
    "```\n",
    "    curl -H \"Content-Type: application/json\" --data '{\"instances\":[\"nintendo 64\"]}' -X POST http://localhost:8501/v1/models/category_classifer:predict\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python usage_api_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion con Tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "\n",
    "class TFLiteModel(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super(TFLiteModel, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=\"string\", name='inputs')])\n",
    "    def __call__(self, inputs, training=False):\n",
    "        logits = self.model(inputs, training=False)\n",
    "        # postprocesamiento de salida\n",
    "        return {\"outputs\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflitemodel_base = TFLiteModel(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\n",
    "keras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "keras_model_converter.allow_custom_ops = True\n",
    "keras_model_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_model = keras_model_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "shutil.rmtree(f\"{MODEL_PATH}\"+os.sep+str(MODEL_VERSION))\n",
    "os.mkdir(f\"{MODEL_PATH}\"+os.sep+str(MODEL_VERSION))\n",
    "\n",
    "with open(f\"{MODEL_PATH}\"+os.sep+str(MODEL_VERSION)+os.sep+\"model.tflite\", \"wb\") as f:    \n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_SIGNATURE = \"serving_default\"\n",
    "REQUIRED_OUTPUT = \"outputs\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(f\"{MODEL_PATH}\"+os.sep+str(MODEL_VERSION)+os.sep+\"model.tflite\")\n",
    "\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "\n",
    "if REQUIRED_SIGNATURE not in found_signatures:\n",
    "    raise KernelEvalException('Required input signature not found.')\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(REQUIRED_SIGNATURE)\n",
    "\n",
    "source_element = np.array([\"Nintendo 64 cartige\", \"pc escritorio\"])\n",
    "\n",
    "output = prediction_fn(inputs=source_element)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volver a crear el docker\n",
    "```\n",
    "    build -t <nombre docker> .\n",
    "```\n",
    "\n",
    "\n",
    "### Ejecutarlo:\n",
    "```\n",
    "    docker run -t --rm -p 8501:8501 <nombre docker> --prefer_tflite_model=true\n",
    "```\n",
    "\n",
    "Necesitamos para este caso agregar --prefer_tflite_model=true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fever_challenge_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
